{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanaAlotaibi/DataScienceProject/blob/main/Data_Collection_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data collection code\n",
        "We used the same code for every year separately. they were executed using diffrent tokens by diffrent students.\n",
        "\n",
        "The actual tokens were written instead of the word \"Token\" in the 7th line but due to security reasons they got replaced in the code.\n"
      ],
      "metadata": {
        "id": "uXPzzRdEiCKI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 2020\n"
      ],
      "metadata": {
        "id": "LqKtm7y6jE5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import re\n",
        "\n",
        "# ==== CONFIG ====\n",
        "GITHUB_TOKEN = 'Token'  # Ø­Ø·Ùˆ Ø­Ù‚ÙƒÙ…\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
        "    \"Accept\": \"application/vnd.github+json\",\n",
        "    \"X-GitHub-Api-Version\": \"2022-11-28\",\n",
        "    \"User-Agent\": \"Data-Science-Project-KSUM\"\n",
        "}\n",
        "\n",
        "QUERY = 'AI OR artificial-intelligence OR machine-learning OR generative-ai'\n",
        "PER_PAGE = 100\n",
        "REPOS_PER_QUARTER = 250  # target per quarter\n",
        "QUARTERS = [\n",
        "    ('2020-01-01', '2020-03-31'),\n",
        "    ('2020-04-01', '2020-06-30'),\n",
        "    ('2020-07-01', '2020-09-30'),\n",
        "    ('2020-10-01', '2020-12-31')\n",
        "]#ØºÙŠØ±Ùˆ Ø§Ù„Ø³Ù†Ù‡ Ù„Ù„Ø³Ù†Ù‡ Ø­Ù‚ØªÙƒÙ…\n",
        "\n",
        "# ==== FUNCTIONS ====\n",
        "\n",
        "def get_repo_details(full_name):\n",
        "    \"\"\"Fetch detailed repo info: languages, topics, license, contributors\"\"\"\n",
        "    repo_details = {'languages': {}, 'topics': [], 'license': None, 'contributors_count': 0}\n",
        "\n",
        "    # Languages\n",
        "    languages_url = f\"https://api.github.com/repos/{full_name}/languages\"\n",
        "    languages_res = requests.get(languages_url, headers=HEADERS)\n",
        "    if languages_res.status_code == 200:\n",
        "        repo_details['languages'] = languages_res.json()\n",
        "\n",
        "    # Topics\n",
        "    topics_url = f\"https://api.github.com/repos/{full_name}/topics\"\n",
        "    topics_headers = HEADERS.copy()\n",
        "    topics_headers['Accept'] = 'application/vnd.github.mercy-preview+json'\n",
        "    topics_res = requests.get(topics_url, headers=topics_headers)\n",
        "    if topics_res.status_code == 200:\n",
        "        repo_details['topics'] = topics_res.json().get('names', [])\n",
        "\n",
        "    # License\n",
        "    repo_url = f\"https://api.github.com/repos/{full_name}\"\n",
        "    repo_res = requests.get(repo_url, headers=HEADERS)\n",
        "    if repo_res.status_code == 200:\n",
        "        repo_data = repo_res.json()\n",
        "        if 'license' in repo_data and repo_data['license']:\n",
        "            repo_details['license'] = repo_data['license'].get('spdx_id')\n",
        "\n",
        "    # Contributors count\n",
        "    contributors_url = f\"https://api.github.com/repos/{full_name}/contributors?per_page=1\"\n",
        "    contributors_res = requests.get(contributors_url, headers=HEADERS)\n",
        "    if contributors_res.status_code == 200:\n",
        "        if 'Link' in contributors_res.headers and 'last' in contributors_res.headers['Link']:\n",
        "            last_page_url = re.search(r'<(.+)>; rel=\"last\"', contributors_res.headers['Link']).group(1)\n",
        "            last_page_number = int(re.search(r'page=(\\d+)', last_page_url).group(1))\n",
        "            repo_details['contributors_count'] = last_page_number\n",
        "        else:\n",
        "            repo_details['contributors_count'] = len(contributors_res.json())\n",
        "\n",
        "    return repo_details\n",
        "\n",
        "def fetch_top_repositories(query, start_date, end_date, per_page=30, max_repos=250):\n",
        "    \"\"\"Fetch repositories sorted by stars in a given date range\"\"\"\n",
        "    repos = []\n",
        "    page = 1\n",
        "    while len(repos) < max_repos:\n",
        "        search_query = f'{query} created:{start_date}..{end_date}'\n",
        "        url = \"https://api.github.com/search/repositories\"\n",
        "        params = {\n",
        "            'q': search_query,\n",
        "            'sort': 'stars',\n",
        "            'order': 'desc',\n",
        "            'per_page': per_page,\n",
        "            'page': page\n",
        "        }\n",
        "        response = requests.get(url, headers=HEADERS, params=params)\n",
        "        if response.status_code != 200:\n",
        "            print(\"Error:\", response.status_code, response.text)\n",
        "            break\n",
        "\n",
        "        items = response.json().get('items', [])\n",
        "        if not items:\n",
        "            break\n",
        "\n",
        "        repos.extend(items)\n",
        "        page += 1\n",
        "        time.sleep(1)\n",
        "\n",
        "    return repos[:max_repos]\n",
        "\n",
        "# ==== MAIN EXECUTION ====\n",
        "if __name__ == '__main__':\n",
        "    all_final_data = []\n",
        "\n",
        "    for start_date, end_date in QUARTERS:\n",
        "        print(f\"ðŸ” Fetching top {REPOS_PER_QUARTER} repos from {start_date} to {end_date}...\")\n",
        "        quarter_repos = fetch_top_repositories(QUERY, start_date, end_date, PER_PAGE, REPOS_PER_QUARTER)\n",
        "\n",
        "        print(f\"ðŸ“¦ Collecting detailed info for {len(quarter_repos)} repos...\")\n",
        "        for item in quarter_repos:\n",
        "            owner = item.get('owner', {}).get('login')\n",
        "            name = item.get('name')\n",
        "            full_name = f\"{owner}/{name}\"\n",
        "\n",
        "            repo_details = get_repo_details(full_name)\n",
        "\n",
        "            repo_info = {\n",
        "                'name': name,\n",
        "                'owner': owner,\n",
        "                'url': item.get('html_url'),\n",
        "                'description': item.get('description'),\n",
        "                'stars': item.get('stargazers_count'),\n",
        "                'forks': item.get('forks_count'),\n",
        "                'created_at': item.get('created_at'),\n",
        "                'pushed_at': item.get('pushed_at'),\n",
        "                'primary_language': item.get('language'),\n",
        "                'all_languages_bytes': repo_details['languages'],\n",
        "                'topics': \", \".join(repo_details['topics']),\n",
        "                'contributors_count': repo_details['contributors_count']\n",
        "            }\n",
        "\n",
        "            all_final_data.append(repo_info)\n",
        "            time.sleep(0.5)\n",
        "\n",
        "    df = pd.DataFrame(all_final_data)\n",
        "    output_filename = \"github_ai_repos_2020_quarters.csv\"#Ø³Ù…ÙˆÙ‡ Ø¨Ø§Ø³Ù… Ø§Ù„Ø³Ù†Ù‡ Ø­Ù‚ØªÙƒÙ…\n",
        "    df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    print(f\"\\nâœ… Completed! Saved {len(df)} repositories to {output_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeXvMyEO58Ec",
        "outputId": "3cb7dd46-7b23-473d-8b12-3a3d8f8e8520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ” Fetching top 251 repos from 2020-01-01 to 2020-03-31...\n",
            "ðŸ“¦ Collecting detailed info for 251 repos...\n",
            "ðŸ” Fetching top 251 repos from 2020-04-01 to 2020-06-30...\n",
            "ðŸ“¦ Collecting detailed info for 251 repos...\n",
            "ðŸ” Fetching top 251 repos from 2020-07-01 to 2020-09-30...\n",
            "ðŸ“¦ Collecting detailed info for 251 repos...\n",
            "ðŸ” Fetching top 251 repos from 2020-10-01 to 2020-12-31...\n",
            "ðŸ“¦ Collecting detailed info for 251 repos...\n",
            "\n",
            "âœ… Completed! Saved 1004 repositories to github_ai_repos_2020_quarters.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 2021"
      ],
      "metadata": {
        "id": "Xe4x-hUOjNWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import re\n",
        "\n",
        "# ==== CONFIG ====\n",
        "GITHUB_TOKEN = 'Token'  # Ø­Ø·Ùˆ Ø­Ù‚ÙƒÙ…\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
        "    \"Accept\": \"application/vnd.github+json\",\n",
        "    \"X-GitHub-Api-Version\": \"2022-11-28\",\n",
        "    \"User-Agent\": \"Data-Science-Project-KSUM\"\n",
        "}\n",
        "\n",
        "QUERY = 'AI OR artificial-intelligence OR machine-learning OR generative-ai'\n",
        "PER_PAGE = 100\n",
        "REPOS_PER_QUARTER = 250  # target per quarter\n",
        "QUARTERS = [\n",
        "    ('2021-01-01', '2021-03-31'),\n",
        "    ('2021-04-01', '2021-06-30'),\n",
        "    ('2021-07-01', '2021-09-30'),\n",
        "    ('2021-10-01', '2021-12-31')\n",
        "]#ØºÙŠØ±Ùˆ Ø§Ù„Ø³Ù†Ù‡ Ù„Ù„Ø³Ù†Ù‡ Ø­Ù‚ØªÙƒÙ…\n",
        "\n",
        "# ==== FUNCTIONS ====\n",
        "\n",
        "def get_repo_details(full_name):\n",
        "    \"\"\"Fetch detailed repo info: languages, topics, license, contributors\"\"\"\n",
        "    repo_details = {'languages': {}, 'topics': [], 'license': None, 'contributors_count': 0}\n",
        "\n",
        "    # Languages\n",
        "    languages_url = f\"https://api.github.com/repos/{full_name}/languages\"\n",
        "    languages_res = requests.get(languages_url, headers=HEADERS)\n",
        "    if languages_res.status_code == 200:\n",
        "        repo_details['languages'] = languages_res.json()\n",
        "\n",
        "    # Topics\n",
        "    topics_url = f\"https://api.github.com/repos/{full_name}/topics\"\n",
        "    topics_headers = HEADERS.copy()\n",
        "    topics_headers['Accept'] = 'application/vnd.github.mercy-preview+json'\n",
        "    topics_res = requests.get(topics_url, headers=topics_headers)\n",
        "    if topics_res.status_code == 200:\n",
        "        repo_details['topics'] = topics_res.json().get('names', [])\n",
        "\n",
        "    # License\n",
        "    repo_url = f\"https://api.github.com/repos/{full_name}\"\n",
        "    repo_res = requests.get(repo_url, headers=HEADERS)\n",
        "    if repo_res.status_code == 200:\n",
        "        repo_data = repo_res.json()\n",
        "        if 'license' in repo_data and repo_data['license']:\n",
        "            repo_details['license'] = repo_data['license'].get('spdx_id')\n",
        "\n",
        "    # Contributors count\n",
        "    contributors_url = f\"https://api.github.com/repos/{full_name}/contributors?per_page=1\"\n",
        "    contributors_res = requests.get(contributors_url, headers=HEADERS)\n",
        "    if contributors_res.status_code == 200:\n",
        "        if 'Link' in contributors_res.headers and 'last' in contributors_res.headers['Link']:\n",
        "            last_page_url = re.search(r'<(.+)>; rel=\"last\"', contributors_res.headers['Link']).group(1)\n",
        "            last_page_number = int(re.search(r'page=(\\d+)', last_page_url).group(1))\n",
        "            repo_details['contributors_count'] = last_page_number\n",
        "        else:\n",
        "            repo_details['contributors_count'] = len(contributors_res.json())\n",
        "\n",
        "    return repo_details\n",
        "\n",
        "def fetch_top_repositories(query, start_date, end_date, per_page=30, max_repos=250):\n",
        "    \"\"\"Fetch repositories sorted by stars in a given date range\"\"\"\n",
        "    repos = []\n",
        "    page = 1\n",
        "    while len(repos) < max_repos:\n",
        "        search_query = f'{query} created:{start_date}..{end_date}'\n",
        "        url = \"https://api.github.com/search/repositories\"\n",
        "        params = {\n",
        "            'q': search_query,\n",
        "            'sort': 'stars',\n",
        "            'order': 'desc',\n",
        "            'per_page': per_page,\n",
        "            'page': page\n",
        "        }\n",
        "        response = requests.get(url, headers=HEADERS, params=params)\n",
        "        if response.status_code != 200:\n",
        "            print(\"Error:\", response.status_code, response.text)\n",
        "            break\n",
        "\n",
        "        items = response.json().get('items', [])\n",
        "        if not items:\n",
        "            break\n",
        "\n",
        "        repos.extend(items)\n",
        "        page += 1\n",
        "        time.sleep(1)\n",
        "\n",
        "    return repos[:max_repos]\n",
        "\n",
        "# ==== MAIN EXECUTION ====\n",
        "if __name__ == '__main__':\n",
        "    all_final_data = []\n",
        "\n",
        "    for start_date, end_date in QUARTERS:\n",
        "        print(f\"ðŸ” Fetching top {REPOS_PER_QUARTER} repos from {start_date} to {end_date}...\")\n",
        "        quarter_repos = fetch_top_repositories(QUERY, start_date, end_date, PER_PAGE, REPOS_PER_QUARTER)\n",
        "\n",
        "        print(f\"ðŸ“¦ Collecting detailed info for {len(quarter_repos)} repos...\")\n",
        "        for item in quarter_repos:\n",
        "            owner = item.get('owner', {}).get('login')\n",
        "            name = item.get('name')\n",
        "            full_name = f\"{owner}/{name}\"\n",
        "\n",
        "            repo_details = get_repo_details(full_name)\n",
        "\n",
        "            repo_info = {\n",
        "                'name': name,\n",
        "                'owner': owner,\n",
        "                'url': item.get('html_url'),\n",
        "                'description': item.get('description'),\n",
        "                'stars': item.get('stargazers_count'),\n",
        "                'forks': item.get('forks_count'),\n",
        "                'created_at': item.get('created_at'),\n",
        "                'pushed_at': item.get('pushed_at'),\n",
        "                'primary_language': item.get('language'),\n",
        "                'all_languages_bytes': repo_details['languages'],\n",
        "                'topics': \", \".join(repo_details['topics']),\n",
        "                'contributors_count': repo_details['contributors_count']\n",
        "            }\n",
        "\n",
        "            all_final_data.append(repo_info)\n",
        "            time.sleep(0.5)\n",
        "\n",
        "    df = pd.DataFrame(all_final_data)\n",
        "    output_filename = \"github_ai_repos_2021_quarters.csv\"#Ø³Ù…ÙˆÙ‡ Ø¨Ø§Ø³Ù… Ø§Ù„Ø³Ù†Ù‡ Ø­Ù‚ØªÙƒÙ…\n",
        "    df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    print(f\"\\nâœ… Completed! Saved {len(df)} repositories to {output_filename}\")"
      ],
      "metadata": {
        "id": "5kOpsjJwjJh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 2022"
      ],
      "metadata": {
        "id": "dsM92VfRjtN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import re\n",
        "\n",
        "# ==== CONFIG ====\n",
        "GITHUB_TOKEN = 'Token'  # Ø­Ø·Ùˆ Ø­Ù‚ÙƒÙ…\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
        "    \"Accept\": \"application/vnd.github+json\",\n",
        "    \"X-GitHub-Api-Version\": \"2022-11-28\",\n",
        "    \"User-Agent\": \"Data-Science-Project-KSUM\"\n",
        "}\n",
        "\n",
        "QUERY = 'AI OR artificial-intelligence OR machine-learning OR generative-ai'\n",
        "PER_PAGE = 100\n",
        "REPOS_PER_QUARTER = 250  # target per quarter\n",
        "QUARTERS = [\n",
        "    ('2022-01-01', '2022-03-31'),\n",
        "    ('2022-04-01', '2022-06-30'),\n",
        "    ('2022-07-01', '2022-09-30'),\n",
        "    ('2022-10-01', '2022-12-31')\n",
        "]#ØºÙŠØ±Ùˆ Ø§Ù„Ø³Ù†Ù‡ Ù„Ù„Ø³Ù†Ù‡ Ø­Ù‚ØªÙƒÙ…\n",
        "\n",
        "# ==== FUNCTIONS ====\n",
        "\n",
        "def get_repo_details(full_name):\n",
        "    \"\"\"Fetch detailed repo info: languages, topics, license, contributors\"\"\"\n",
        "    repo_details = {'languages': {}, 'topics': [], 'license': None, 'contributors_count': 0}\n",
        "\n",
        "    # Languages\n",
        "    languages_url = f\"https://api.github.com/repos/{full_name}/languages\"\n",
        "    languages_res = requests.get(languages_url, headers=HEADERS)\n",
        "    if languages_res.status_code == 200:\n",
        "        repo_details['languages'] = languages_res.json()\n",
        "\n",
        "    # Topics\n",
        "    topics_url = f\"https://api.github.com/repos/{full_name}/topics\"\n",
        "    topics_headers = HEADERS.copy()\n",
        "    topics_headers['Accept'] = 'application/vnd.github.mercy-preview+json'\n",
        "    topics_res = requests.get(topics_url, headers=topics_headers)\n",
        "    if topics_res.status_code == 200:\n",
        "        repo_details['topics'] = topics_res.json().get('names', [])\n",
        "\n",
        "    # License\n",
        "    repo_url = f\"https://api.github.com/repos/{full_name}\"\n",
        "    repo_res = requests.get(repo_url, headers=HEADERS)\n",
        "    if repo_res.status_code == 200:\n",
        "        repo_data = repo_res.json()\n",
        "        if 'license' in repo_data and repo_data['license']:\n",
        "            repo_details['license'] = repo_data['license'].get('spdx_id')\n",
        "\n",
        "    # Contributors count\n",
        "    contributors_url = f\"https://api.github.com/repos/{full_name}/contributors?per_page=1\"\n",
        "    contributors_res = requests.get(contributors_url, headers=HEADERS)\n",
        "    if contributors_res.status_code == 200:\n",
        "        if 'Link' in contributors_res.headers and 'last' in contributors_res.headers['Link']:\n",
        "            last_page_url = re.search(r'<(.+)>; rel=\"last\"', contributors_res.headers['Link']).group(1)\n",
        "            last_page_number = int(re.search(r'page=(\\d+)', last_page_url).group(1))\n",
        "            repo_details['contributors_count'] = last_page_number\n",
        "        else:\n",
        "            repo_details['contributors_count'] = len(contributors_res.json())\n",
        "\n",
        "    return repo_details\n",
        "\n",
        "def fetch_top_repositories(query, start_date, end_date, per_page=30, max_repos=250):\n",
        "    \"\"\"Fetch repositories sorted by stars in a given date range\"\"\"\n",
        "    repos = []\n",
        "    page = 1\n",
        "    while len(repos) < max_repos:\n",
        "        search_query = f'{query} created:{start_date}..{end_date}'\n",
        "        url = \"https://api.github.com/search/repositories\"\n",
        "        params = {\n",
        "            'q': search_query,\n",
        "            'sort': 'stars',\n",
        "            'order': 'desc',\n",
        "            'per_page': per_page,\n",
        "            'page': page\n",
        "        }\n",
        "        response = requests.get(url, headers=HEADERS, params=params)\n",
        "        if response.status_code != 200:\n",
        "            print(\"Error:\", response.status_code, response.text)\n",
        "            break\n",
        "\n",
        "        items = response.json().get('items', [])\n",
        "        if not items:\n",
        "            break\n",
        "\n",
        "        repos.extend(items)\n",
        "        page += 1\n",
        "        time.sleep(1)\n",
        "\n",
        "    return repos[:max_repos]\n",
        "\n",
        "# ==== MAIN EXECUTION ====\n",
        "if __name__ == '__main__':\n",
        "    all_final_data = []\n",
        "\n",
        "    for start_date, end_date in QUARTERS:\n",
        "        print(f\"ðŸ” Fetching top {REPOS_PER_QUARTER} repos from {start_date} to {end_date}...\")\n",
        "        quarter_repos = fetch_top_repositories(QUERY, start_date, end_date, PER_PAGE, REPOS_PER_QUARTER)\n",
        "\n",
        "        print(f\"ðŸ“¦ Collecting detailed info for {len(quarter_repos)} repos...\")\n",
        "        for item in quarter_repos:\n",
        "            owner = item.get('owner', {}).get('login')\n",
        "            name = item.get('name')\n",
        "            full_name = f\"{owner}/{name}\"\n",
        "\n",
        "            repo_details = get_repo_details(full_name)\n",
        "\n",
        "            repo_info = {\n",
        "                'name': name,\n",
        "                'owner': owner,\n",
        "                'url': item.get('html_url'),\n",
        "                'description': item.get('description'),\n",
        "                'stars': item.get('stargazers_count'),\n",
        "                'forks': item.get('forks_count'),\n",
        "                'created_at': item.get('created_at'),\n",
        "                'pushed_at': item.get('pushed_at'),\n",
        "                'primary_language': item.get('language'),\n",
        "                'all_languages_bytes': repo_details['languages'],\n",
        "                'topics': \", \".join(repo_details['topics']),\n",
        "                'contributors_count': repo_details['contributors_count']\n",
        "            }\n",
        "\n",
        "            all_final_data.append(repo_info)\n",
        "            time.sleep(0.5)\n",
        "\n",
        "    df = pd.DataFrame(all_final_data)\n",
        "    output_filename = \"github_ai_repos_2022_quarters.csv\"#Ø³Ù…ÙˆÙ‡ Ø¨Ø§Ø³Ù… Ø§Ù„Ø³Ù†Ù‡ Ø­Ù‚ØªÙƒÙ…\n",
        "    df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    print(f\"\\nâœ… Completed! Saved {len(df)} repositories to {output_filename}\")"
      ],
      "metadata": {
        "id": "L9I_hfgzjuXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 2023"
      ],
      "metadata": {
        "id": "yyMKRZoBj6y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import re\n",
        "\n",
        "# ==== CONFIG ====\n",
        "GITHUB_TOKEN = 'Token'  # Ø­Ø·Ùˆ Ø­Ù‚ÙƒÙ…\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
        "    \"Accept\": \"application/vnd.github+json\",\n",
        "    \"X-GitHub-Api-Version\": \"2022-11-28\",\n",
        "    \"User-Agent\": \"Data-Science-Project-KSUM\"\n",
        "}\n",
        "\n",
        "QUERY = 'AI OR artificial-intelligence OR machine-learning OR generative-ai'\n",
        "PER_PAGE = 100\n",
        "REPOS_PER_QUARTER = 250  # target per quarter\n",
        "QUARTERS = [\n",
        "    ('2023-01-01', '2023-03-31'),\n",
        "    ('2023-04-01', '2023-06-30'),\n",
        "    ('2023-07-01', '2023-09-30'),\n",
        "    ('2023-10-01', '2023-12-31')\n",
        "]#ØºÙŠØ±Ùˆ Ø§Ù„Ø³Ù†Ù‡ Ù„Ù„Ø³Ù†Ù‡ Ø­Ù‚ØªÙƒÙ…\n",
        "\n",
        "# ==== FUNCTIONS ====\n",
        "\n",
        "def get_repo_details(full_name):\n",
        "    \"\"\"Fetch detailed repo info: languages, topics, license, contributors\"\"\"\n",
        "    repo_details = {'languages': {}, 'topics': [], 'license': None, 'contributors_count': 0}\n",
        "\n",
        "    # Languages\n",
        "    languages_url = f\"https://api.github.com/repos/{full_name}/languages\"\n",
        "    languages_res = requests.get(languages_url, headers=HEADERS)\n",
        "    if languages_res.status_code == 200:\n",
        "        repo_details['languages'] = languages_res.json()\n",
        "\n",
        "    # Topics\n",
        "    topics_url = f\"https://api.github.com/repos/{full_name}/topics\"\n",
        "    topics_headers = HEADERS.copy()\n",
        "    topics_headers['Accept'] = 'application/vnd.github.mercy-preview+json'\n",
        "    topics_res = requests.get(topics_url, headers=topics_headers)\n",
        "    if topics_res.status_code == 200:\n",
        "        repo_details['topics'] = topics_res.json().get('names', [])\n",
        "\n",
        "    # License\n",
        "    repo_url = f\"https://api.github.com/repos/{full_name}\"\n",
        "    repo_res = requests.get(repo_url, headers=HEADERS)\n",
        "    if repo_res.status_code == 200:\n",
        "        repo_data = repo_res.json()\n",
        "        if 'license' in repo_data and repo_data['license']:\n",
        "            repo_details['license'] = repo_data['license'].get('spdx_id')\n",
        "\n",
        "    # Contributors count\n",
        "    contributors_url = f\"https://api.github.com/repos/{full_name}/contributors?per_page=1\"\n",
        "    contributors_res = requests.get(contributors_url, headers=HEADERS)\n",
        "    if contributors_res.status_code == 200:\n",
        "        if 'Link' in contributors_res.headers and 'last' in contributors_res.headers['Link']:\n",
        "            last_page_url = re.search(r'<(.+)>; rel=\"last\"', contributors_res.headers['Link']).group(1)\n",
        "            last_page_number = int(re.search(r'page=(\\d+)', last_page_url).group(1))\n",
        "            repo_details['contributors_count'] = last_page_number\n",
        "        else:\n",
        "            repo_details['contributors_count'] = len(contributors_res.json())\n",
        "\n",
        "    return repo_details\n",
        "\n",
        "def fetch_top_repositories(query, start_date, end_date, per_page=30, max_repos=250):\n",
        "    \"\"\"Fetch repositories sorted by stars in a given date range\"\"\"\n",
        "    repos = []\n",
        "    page = 1\n",
        "    while len(repos) < max_repos:\n",
        "        search_query = f'{query} created:{start_date}..{end_date}'\n",
        "        url = \"https://api.github.com/search/repositories\"\n",
        "        params = {\n",
        "            'q': search_query,\n",
        "            'sort': 'stars',\n",
        "            'order': 'desc',\n",
        "            'per_page': per_page,\n",
        "            'page': page\n",
        "        }\n",
        "        response = requests.get(url, headers=HEADERS, params=params)\n",
        "        if response.status_code != 200:\n",
        "            print(\"Error:\", response.status_code, response.text)\n",
        "            break\n",
        "\n",
        "        items = response.json().get('items', [])\n",
        "        if not items:\n",
        "            break\n",
        "\n",
        "        repos.extend(items)\n",
        "        page += 1\n",
        "        time.sleep(1)\n",
        "\n",
        "    return repos[:max_repos]\n",
        "\n",
        "# ==== MAIN EXECUTION ====\n",
        "if __name__ == '__main__':\n",
        "    all_final_data = []\n",
        "\n",
        "    for start_date, end_date in QUARTERS:\n",
        "        print(f\"ðŸ” Fetching top {REPOS_PER_QUARTER} repos from {start_date} to {end_date}...\")\n",
        "        quarter_repos = fetch_top_repositories(QUERY, start_date, end_date, PER_PAGE, REPOS_PER_QUARTER)\n",
        "\n",
        "        print(f\"ðŸ“¦ Collecting detailed info for {len(quarter_repos)} repos...\")\n",
        "        for item in quarter_repos:\n",
        "            owner = item.get('owner', {}).get('login')\n",
        "            name = item.get('name')\n",
        "            full_name = f\"{owner}/{name}\"\n",
        "\n",
        "            repo_details = get_repo_details(full_name)\n",
        "\n",
        "            repo_info = {\n",
        "                'name': name,\n",
        "                'owner': owner,\n",
        "                'url': item.get('html_url'),\n",
        "                'description': item.get('description'),\n",
        "                'stars': item.get('stargazers_count'),\n",
        "                'forks': item.get('forks_count'),\n",
        "                'created_at': item.get('created_at'),\n",
        "                'pushed_at': item.get('pushed_at'),\n",
        "                'primary_language': item.get('language'),\n",
        "                'all_languages_bytes': repo_details['languages'],\n",
        "                'topics': \", \".join(repo_details['topics']),\n",
        "                'contributors_count': repo_details['contributors_count']\n",
        "            }\n",
        "\n",
        "            all_final_data.append(repo_info)\n",
        "            time.sleep(0.5)\n",
        "\n",
        "    df = pd.DataFrame(all_final_data)\n",
        "    output_filename = \"github_ai_repos_2023_quarters.csv\"#Ø³Ù…ÙˆÙ‡ Ø¨Ø§Ø³Ù… Ø§Ù„Ø³Ù†Ù‡ Ø­Ù‚ØªÙƒÙ…\n",
        "    df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    print(f\"\\nâœ… Completed! Saved {len(df)} repositories to {output_filename}\")"
      ],
      "metadata": {
        "id": "tzcOMiC1j8Fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 2024"
      ],
      "metadata": {
        "id": "fSqz2tVFkGe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import re\n",
        "\n",
        "# ==== CONFIG ====\n",
        "GITHUB_TOKEN = 'Token'  # Ø­Ø·Ùˆ Ø­Ù‚ÙƒÙ…\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
        "    \"Accept\": \"application/vnd.github+json\",\n",
        "    \"X-GitHub-Api-Version\": \"2022-11-28\",\n",
        "    \"User-Agent\": \"Data-Science-Project-KSUM\"\n",
        "}\n",
        "\n",
        "QUERY = 'AI OR artificial-intelligence OR machine-learning OR generative-ai'\n",
        "PER_PAGE = 100\n",
        "REPOS_PER_QUARTER = 250  # target per quarter\n",
        "QUARTERS = [\n",
        "    ('2024-01-01', '2024-03-31'),\n",
        "    ('2024-04-01', '2024-06-30'),\n",
        "    ('2024-07-01', '2024-09-30'),\n",
        "    ('2024-10-01', '2024-12-31')\n",
        "]#ØºÙŠØ±Ùˆ Ø§Ù„Ø³Ù†Ù‡ Ù„Ù„Ø³Ù†Ù‡ Ø­Ù‚ØªÙƒÙ…\n",
        "\n",
        "# ==== FUNCTIONS ====\n",
        "\n",
        "def get_repo_details(full_name):\n",
        "    \"\"\"Fetch detailed repo info: languages, topics, license, contributors\"\"\"\n",
        "    repo_details = {'languages': {}, 'topics': [], 'license': None, 'contributors_count': 0}\n",
        "\n",
        "    # Languages\n",
        "    languages_url = f\"https://api.github.com/repos/{full_name}/languages\"\n",
        "    languages_res = requests.get(languages_url, headers=HEADERS)\n",
        "    if languages_res.status_code == 200:\n",
        "        repo_details['languages'] = languages_res.json()\n",
        "\n",
        "    # Topics\n",
        "    topics_url = f\"https://api.github.com/repos/{full_name}/topics\"\n",
        "    topics_headers = HEADERS.copy()\n",
        "    topics_headers['Accept'] = 'application/vnd.github.mercy-preview+json'\n",
        "    topics_res = requests.get(topics_url, headers=topics_headers)\n",
        "    if topics_res.status_code == 200:\n",
        "        repo_details['topics'] = topics_res.json().get('names', [])\n",
        "\n",
        "    # License\n",
        "    repo_url = f\"https://api.github.com/repos/{full_name}\"\n",
        "    repo_res = requests.get(repo_url, headers=HEADERS)\n",
        "    if repo_res.status_code == 200:\n",
        "        repo_data = repo_res.json()\n",
        "        if 'license' in repo_data and repo_data['license']:\n",
        "            repo_details['license'] = repo_data['license'].get('spdx_id')\n",
        "\n",
        "    # Contributors count\n",
        "    contributors_url = f\"https://api.github.com/repos/{full_name}/contributors?per_page=1\"\n",
        "    contributors_res = requests.get(contributors_url, headers=HEADERS)\n",
        "    if contributors_res.status_code == 200:\n",
        "        if 'Link' in contributors_res.headers and 'last' in contributors_res.headers['Link']:\n",
        "            last_page_url = re.search(r'<(.+)>; rel=\"last\"', contributors_res.headers['Link']).group(1)\n",
        "            last_page_number = int(re.search(r'page=(\\d+)', last_page_url).group(1))\n",
        "            repo_details['contributors_count'] = last_page_number\n",
        "        else:\n",
        "            repo_details['contributors_count'] = len(contributors_res.json())\n",
        "\n",
        "    return repo_details\n",
        "\n",
        "def fetch_top_repositories(query, start_date, end_date, per_page=30, max_repos=250):\n",
        "    \"\"\"Fetch repositories sorted by stars in a given date range\"\"\"\n",
        "    repos = []\n",
        "    page = 1\n",
        "    while len(repos) < max_repos:\n",
        "        search_query = f'{query} created:{start_date}..{end_date}'\n",
        "        url = \"https://api.github.com/search/repositories\"\n",
        "        params = {\n",
        "            'q': search_query,\n",
        "            'sort': 'stars',\n",
        "            'order': 'desc',\n",
        "            'per_page': per_page,\n",
        "            'page': page\n",
        "        }\n",
        "        response = requests.get(url, headers=HEADERS, params=params)\n",
        "        if response.status_code != 200:\n",
        "            print(\"Error:\", response.status_code, response.text)\n",
        "            break\n",
        "\n",
        "        items = response.json().get('items', [])\n",
        "        if not items:\n",
        "            break\n",
        "\n",
        "        repos.extend(items)\n",
        "        page += 1\n",
        "        time.sleep(1)\n",
        "\n",
        "    return repos[:max_repos]\n",
        "\n",
        "# ==== MAIN EXECUTION ====\n",
        "if __name__ == '__main__':\n",
        "    all_final_data = []\n",
        "\n",
        "    for start_date, end_date in QUARTERS:\n",
        "        print(f\"ðŸ” Fetching top {REPOS_PER_QUARTER} repos from {start_date} to {end_date}...\")\n",
        "        quarter_repos = fetch_top_repositories(QUERY, start_date, end_date, PER_PAGE, REPOS_PER_QUARTER)\n",
        "\n",
        "        print(f\"ðŸ“¦ Collecting detailed info for {len(quarter_repos)} repos...\")\n",
        "        for item in quarter_repos:\n",
        "            owner = item.get('owner', {}).get('login')\n",
        "            name = item.get('name')\n",
        "            full_name = f\"{owner}/{name}\"\n",
        "\n",
        "            repo_details = get_repo_details(full_name)\n",
        "\n",
        "            repo_info = {\n",
        "                'name': name,\n",
        "                'owner': owner,\n",
        "                'url': item.get('html_url'),\n",
        "                'description': item.get('description'),\n",
        "                'stars': item.get('stargazers_count'),\n",
        "                'forks': item.get('forks_count'),\n",
        "                'created_at': item.get('created_at'),\n",
        "                'pushed_at': item.get('pushed_at'),\n",
        "                'primary_language': item.get('language'),\n",
        "                'all_languages_bytes': repo_details['languages'],\n",
        "                'topics': \", \".join(repo_details['topics']),\n",
        "                'contributors_count': repo_details['contributors_count']\n",
        "            }\n",
        "\n",
        "            all_final_data.append(repo_info)\n",
        "            time.sleep(0.5)\n",
        "\n",
        "    df = pd.DataFrame(all_final_data)\n",
        "    output_filename = \"github_ai_repos_2024_quarters.csv\"#Ø³Ù…ÙˆÙ‡ Ø¨Ø§Ø³Ù… Ø§Ù„Ø³Ù†Ù‡ Ø­Ù‚ØªÙƒÙ…\n",
        "    df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    print(f\"\\nâœ… Completed! Saved {len(df)} repositories to {output_filename}\")"
      ],
      "metadata": {
        "id": "A070mnU3kPo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 2025"
      ],
      "metadata": {
        "id": "p_yKYweDkbIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import re\n",
        "\n",
        "# ==== CONFIG ====\n",
        "GITHUB_TOKEN = 'Token'  # Ø­Ø·Ùˆ Ø­Ù‚ÙƒÙ…\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
        "    \"Accept\": \"application/vnd.github+json\",\n",
        "    \"X-GitHub-Api-Version\": \"2022-11-28\",\n",
        "    \"User-Agent\": \"Data-Science-Project-KSUM\"\n",
        "}\n",
        "\n",
        "QUERY = 'AI OR artificial-intelligence OR machine-learning OR generative-ai'\n",
        "PER_PAGE = 100\n",
        "REPOS_PER_QUARTER = 250  # target per quarter\n",
        "QUARTERS = [\n",
        "    ('2025-01-01', '2025-03-31'),\n",
        "    ('2025-04-01', '2025-06-30'),\n",
        "    ('2025-07-01', '2025-09-23'),\n",
        "]#ØºÙŠØ±Ùˆ Ø§Ù„Ø³Ù†Ù‡ Ù„Ù„Ø³Ù†Ù‡ Ø­Ù‚ØªÙƒÙ…\n",
        "\n",
        "# ==== FUNCTIONS ====\n",
        "\n",
        "def get_repo_details(full_name):\n",
        "    \"\"\"Fetch detailed repo info: languages, topics, license, contributors\"\"\"\n",
        "    repo_details = {'languages': {}, 'topics': [], 'license': None, 'contributors_count': 0}\n",
        "\n",
        "    # Languages\n",
        "    languages_url = f\"https://api.github.com/repos/{full_name}/languages\"\n",
        "    languages_res = requests.get(languages_url, headers=HEADERS)\n",
        "    if languages_res.status_code == 200:\n",
        "        repo_details['languages'] = languages_res.json()\n",
        "\n",
        "    # Topics\n",
        "    topics_url = f\"https://api.github.com/repos/{full_name}/topics\"\n",
        "    topics_headers = HEADERS.copy()\n",
        "    topics_headers['Accept'] = 'application/vnd.github.mercy-preview+json'\n",
        "    topics_res = requests.get(topics_url, headers=topics_headers)\n",
        "    if topics_res.status_code == 200:\n",
        "        repo_details['topics'] = topics_res.json().get('names', [])\n",
        "\n",
        "    # License\n",
        "    repo_url = f\"https://api.github.com/repos/{full_name}\"\n",
        "    repo_res = requests.get(repo_url, headers=HEADERS)\n",
        "    if repo_res.status_code == 200:\n",
        "        repo_data = repo_res.json()\n",
        "        if 'license' in repo_data and repo_data['license']:\n",
        "            repo_details['license'] = repo_data['license'].get('spdx_id')\n",
        "\n",
        "    # Contributors count\n",
        "    contributors_url = f\"https://api.github.com/repos/{full_name}/contributors?per_page=1\"\n",
        "    contributors_res = requests.get(contributors_url, headers=HEADERS)\n",
        "    if contributors_res.status_code == 200:\n",
        "        if 'Link' in contributors_res.headers and 'last' in contributors_res.headers['Link']:\n",
        "            last_page_url = re.search(r'<(.+)>; rel=\"last\"', contributors_res.headers['Link']).group(1)\n",
        "            last_page_number = int(re.search(r'page=(\\d+)', last_page_url).group(1))\n",
        "            repo_details['contributors_count'] = last_page_number\n",
        "        else:\n",
        "            repo_details['contributors_count'] = len(contributors_res.json())\n",
        "\n",
        "    return repo_details\n",
        "\n",
        "def fetch_top_repositories(query, start_date, end_date, per_page=30, max_repos=250):\n",
        "    \"\"\"Fetch repositories sorted by stars in a given date range\"\"\"\n",
        "    repos = []\n",
        "    page = 1\n",
        "    while len(repos) < max_repos:\n",
        "        search_query = f'{query} created:{start_date}..{end_date}'\n",
        "        url = \"https://api.github.com/search/repositories\"\n",
        "        params = {\n",
        "            'q': search_query,\n",
        "            'sort': 'stars',\n",
        "            'order': 'desc',\n",
        "            'per_page': per_page,\n",
        "            'page': page\n",
        "        }\n",
        "        response = requests.get(url, headers=HEADERS, params=params)\n",
        "        if response.status_code != 200:\n",
        "            print(\"Error:\", response.status_code, response.text)\n",
        "            break\n",
        "\n",
        "        items = response.json().get('items', [])\n",
        "        if not items:\n",
        "            break\n",
        "\n",
        "        repos.extend(items)\n",
        "        page += 1\n",
        "        time.sleep(1)\n",
        "\n",
        "    return repos[:max_repos]\n",
        "\n",
        "# ==== MAIN EXECUTION ====\n",
        "if __name__ == '__main__':\n",
        "    all_final_data = []\n",
        "\n",
        "    for start_date, end_date in QUARTERS:\n",
        "        print(f\"ðŸ” Fetching top {REPOS_PER_QUARTER} repos from {start_date} to {end_date}...\")\n",
        "        quarter_repos = fetch_top_repositories(QUERY, start_date, end_date, PER_PAGE, REPOS_PER_QUARTER)\n",
        "\n",
        "        print(f\"ðŸ“¦ Collecting detailed info for {len(quarter_repos)} repos...\")\n",
        "        for item in quarter_repos:\n",
        "            owner = item.get('owner', {}).get('login')\n",
        "            name = item.get('name')\n",
        "            full_name = f\"{owner}/{name}\"\n",
        "\n",
        "            repo_details = get_repo_details(full_name)\n",
        "\n",
        "            repo_info = {\n",
        "                'name': name,\n",
        "                'owner': owner,\n",
        "                'url': item.get('html_url'),\n",
        "                'description': item.get('description'),\n",
        "                'stars': item.get('stargazers_count'),\n",
        "                'forks': item.get('forks_count'),\n",
        "                'created_at': item.get('created_at'),\n",
        "                'pushed_at': item.get('pushed_at'),\n",
        "                'primary_language': item.get('language'),\n",
        "                'all_languages_bytes': repo_details['languages'],\n",
        "                'topics': \", \".join(repo_details['topics']),\n",
        "                'contributors_count': repo_details['contributors_count']\n",
        "            }\n",
        "\n",
        "            all_final_data.append(repo_info)\n",
        "            time.sleep(0.5)\n",
        "\n",
        "    df = pd.DataFrame(all_final_data)\n",
        "    output_filename = \"github_ai_repos_2025_quarters.csv\"#Ø³Ù…ÙˆÙ‡ Ø¨Ø§Ø³Ù… Ø§Ù„Ø³Ù†Ù‡ Ø­Ù‚ØªÙƒÙ…\n",
        "    df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    print(f\"\\nâœ… Completed! Saved {len(df)} repositories to {output_filename}\")"
      ],
      "metadata": {
        "id": "noluZouOkcm8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}